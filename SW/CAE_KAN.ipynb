{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDb4gk7OVF0l"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from pylab import *\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import griddata\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-lu5oIdVJ1-",
        "outputId": "5d2d7f41-ba95-4a28-8dfd-7475cadf6544"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "content_path = '/content/gdrive/MyDrive/ic_project/new'\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3OiRbTGXJYa"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from pylab import *\n",
        "import matplotlib.gridspec as gridspec\n",
        "import numpy as np\n",
        "#construct background states, observations with error\n",
        "\n",
        "def x_to_y(X): # averaging in 2*2 windows (4 pixels)\n",
        "    dim = X.shape[0]\n",
        "    dim = 20\n",
        "    Y = np.zeros((int(dim/2),int(dim/2)))\n",
        "    for i in range(int(dim/2)):\n",
        "        for j in range(int(dim/2)):\n",
        "            Y[i,j] = X[2*i,2*j] + X[2*i+1,2*j] + X[2*i,2*j+1] + X[2*i+1,2*j+1]\n",
        "\n",
        "            Y_noise = np.random.multivariate_normal(np.zeros(100),0.0000 * np.eye(100))\n",
        "            Y_noise.shape = (10,10)\n",
        "            Y = Y + Y_noise\n",
        "    return Y\n",
        "\n",
        "\n",
        "class shallow(object):\n",
        "\n",
        "\n",
        "    time = 0\n",
        "\n",
        "    plt = []\n",
        "    fig = []\n",
        "\n",
        "\n",
        "    def __init__(self, x=[],y=[],h_ini = 1.,u=[],v = [],dx=0.01,dt=0.0001, N=64,L=1., px=16, py=16, R=64, Hp=0.1, g=1., b=0.): # How define no default argument before?\n",
        "\n",
        "\n",
        "        # add a perturbation in pressure surface\n",
        "\n",
        "\n",
        "        self.px, self.py = px, py\n",
        "        self.R = R\n",
        "        self.Hp = Hp\n",
        "\n",
        "\n",
        "\n",
        "        # Physical parameters\n",
        "\n",
        "        self.g = g\n",
        "        self.b = b\n",
        "        self.L=L\n",
        "        self.N=N\n",
        "\n",
        "        # limits for h,u,v\n",
        "\n",
        "\n",
        "        #self.dx =  self.L / self.N # a changer\n",
        "        #self.dt = self.dx / 100.\n",
        "        self.dx=dx\n",
        "        self.dt=dt\n",
        "\n",
        "        self.x,self.y = mgrid[:self.N,:self.N]\n",
        "\n",
        "        self.u=zeros((self.N,self.N))\n",
        "        self.v=zeros((self.N,self.N))\n",
        "\n",
        "        self.h_ini=h_ini\n",
        "\n",
        "        self.h=self.h_ini * ones((self.N,self.N))\n",
        "\n",
        "        rr = (self.x-px)**2 + (self.y-py)**2\n",
        "        self.h[rr<R] = self.h_ini + Hp #set initial conditions\n",
        "\n",
        "        self.lims = [(self.h_ini-self.Hp,self.h_ini+self.Hp),(-0.02,0.02),(-0.02,0.02)]\n",
        "\n",
        "\n",
        "\n",
        "    def dxy(self, A, axis=0):\n",
        "        \"\"\"\n",
        "        Compute derivative of array A using balanced finite differences\n",
        "        Axis specifies direction of spatial derivative (d/dx or d/dy)\n",
        "        dA[i]/dx =  (A[i+1] - A[i-1] )  / 2dx\n",
        "        \"\"\"\n",
        "        return (roll(A, -1, axis) - roll(A, 1, axis)) / (self.dx*2.) # roll: shift the array axis=0 shift the horizontal axis\n",
        "\n",
        "    def d_dx(self, A):\n",
        "        return self.dxy(A,1)\n",
        "\n",
        "    def d_dy(self, A):\n",
        "        return self.dxy(A,0)\n",
        "\n",
        "\n",
        "    def d_dt(self, h, u, v):\n",
        "        \"\"\"\n",
        "        http://en.wikipedia.org/wiki/Shallow_water_equations#Non-conservative_form\n",
        "        \"\"\"\n",
        "        for x in [h, u, v]: # type check\n",
        "           assert isinstance(x, ndarray) and not isinstance(x, matrix)\n",
        "\n",
        "        g,b,dx = self.g, self.b, self.dx\n",
        "\n",
        "        du_dt = -g*self.d_dx(h) - b*u\n",
        "        dv_dt = -g*self.d_dy(h) - b*v\n",
        "\n",
        "        H = 0 #h.mean() - our definition of h includes this term\n",
        "        dh_dt = -self.d_dx(u * (H+h)) - self.d_dy(v * (H+h))\n",
        "\n",
        "        return dh_dt, du_dt, dv_dt\n",
        "\n",
        "\n",
        "    def evolve(self):\n",
        "        \"\"\"\n",
        "        Evolve state (h, u, v) forward in time using simple Euler method\n",
        "        x_{N+1} = x_{N} +   dx/dt * d_t\n",
        "        \"\"\"\n",
        "\n",
        "        dh_dt, du_dt, dv_dt = self.d_dt(self.h, self.u, self.v)\n",
        "        dt = self.dt\n",
        "\n",
        "        self.h += dh_dt * dt\n",
        "        self.u += du_dt * dt\n",
        "        self.v += dv_dt * dt\n",
        "        self.time += dt\n",
        "\n",
        "        return self.h, self.u, self.v\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NCH4bscVq4m6",
        "outputId": "111a0555-a1c1-4ef9-cb6c-edca4b8bfae6"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "# Generate the dataset\n",
        "def generate_dataset(num_simulations=200, snapshots_per_simulation=5000, N=64):\n",
        "    dataset = np.zeros((num_simulations * (snapshots_per_simulation//50), 3, N, N))\n",
        "    first_snapshots = np.zeros((num_simulations, 3, N, N))\n",
        "    snapshot_idx = 0\n",
        "\n",
        "    for sim in range(num_simulations):\n",
        "        px=random.randint(54, 74)*1.\n",
        "        py=random.randint(54, 74)*1.\n",
        "        R=random.randint(80, 160)*1.\n",
        "        Hp=random.randint(5, 20)*0.01\n",
        "        b=random.randint(1, 100)*0.1\n",
        "\n",
        "        SW = shallow(N=N, px=px, py=py, R=R, Hp=Hp, b=b)\n",
        "        print(\"sim\",sim)\n",
        "\n",
        "        for step in range(snapshots_per_simulation):\n",
        "            SW.evolve()\n",
        "            if (step)%50==0:\n",
        "\n",
        "              dataset[snapshot_idx, 0, :, :] = SW.u\n",
        "              dataset[snapshot_idx, 1, :, :] = SW.v\n",
        "              dataset[snapshot_idx, 2, :, :] = SW.h\n",
        "              snapshot_idx += 1\n",
        "\n",
        "              # Save the first snapshot of the simulation\n",
        "              if step == snapshots_per_simulation-1:\n",
        "                  first_snapshots[sim, 0, :, :] = SW.u\n",
        "                  first_snapshots[sim, 1, :, :] = SW.v\n",
        "                  first_snapshots[sim, 2, :, :] = SW.h\n",
        "\n",
        "\n",
        "    return dataset,first_snapshots\n",
        "\n",
        "#apply min_max normalization\n",
        "def min_max_normalize(dataset):\n",
        "    u_min = dataset[:, 0, :, :].min()\n",
        "    u_max = dataset[:, 0, :, :].max()\n",
        "    v_min = dataset[:, 1, :, :].min()\n",
        "    v_max = dataset[:, 1, :, :].max()\n",
        "    h_min = dataset[:, 2, :, :].min()\n",
        "    h_max = dataset[:, 2, :, :].max()\n",
        "\n",
        "    dataset[:, 0, :, :] = (dataset[:, 0, :, :] - u_min) / (u_max - u_min)\n",
        "    dataset[:, 1, :, :] = (dataset[:, 1, :, :] - v_min) / (v_max - v_min)\n",
        "    dataset[:, 2, :, :] = (dataset[:, 2, :, :] - h_min) / (h_max - h_min)\n",
        "\n",
        "    return dataset, (u_min, u_max, v_min, v_max, h_min, h_max)\n",
        "\n",
        "# Generate the dataset\n",
        "dataset,first_snapshots = generate_dataset(num_simulations=200, snapshots_per_simulation=5000, N=128)\n",
        "dataset_norm, normalization_params= min_max_normalize(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define KAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpiFoBzDVpgn"
      },
      "outputs": [],
      "source": [
        "\n",
        "class KANLinear(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features,\n",
        "        out_features,\n",
        "        grid_size=5,\n",
        "        spline_order=3,\n",
        "        scale_noise=0.1,\n",
        "        scale_base=1.0,\n",
        "        scale_spline=1.0,\n",
        "        enable_standalone_scale_spline=True,\n",
        "        base_activation=torch.nn.SiLU,\n",
        "        grid_eps=0.02,\n",
        "        grid_range=[-1, 1],\n",
        "    ):\n",
        "        super(KANLinear, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.grid_size = grid_size\n",
        "        self.spline_order = spline_order\n",
        "\n",
        "        h = (grid_range[1] - grid_range[0]) / grid_size\n",
        "        grid = (\n",
        "            (\n",
        "                torch.arange(-spline_order, grid_size + spline_order + 1) * h\n",
        "                + grid_range[0]\n",
        "            )\n",
        "            .expand(in_features, -1)\n",
        "            .contiguous()\n",
        "        )\n",
        "        self.register_buffer(\"grid\", grid)\n",
        "\n",
        "        self.base_weight = torch.nn.Parameter(torch.Tensor(out_features, in_features))\n",
        "        self.spline_weight = torch.nn.Parameter(\n",
        "            torch.Tensor(out_features, in_features, grid_size + spline_order)\n",
        "        )\n",
        "        if enable_standalone_scale_spline:\n",
        "            self.spline_scaler = torch.nn.Parameter(\n",
        "                torch.Tensor(out_features, in_features)\n",
        "            )\n",
        "\n",
        "        self.scale_noise = scale_noise\n",
        "        self.scale_base = scale_base\n",
        "        self.scale_spline = scale_spline\n",
        "        self.enable_standalone_scale_spline = enable_standalone_scale_spline\n",
        "        self.base_activation = base_activation()\n",
        "        self.grid_eps = grid_eps\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        torch.nn.init.kaiming_uniform_(self.base_weight, a=math.sqrt(5) * self.scale_base)\n",
        "        with torch.no_grad():\n",
        "            noise = (\n",
        "                (\n",
        "                    torch.rand(self.grid_size + 1, self.in_features, self.out_features)\n",
        "                    - 1 / 2\n",
        "                )\n",
        "                * self.scale_noise\n",
        "                / self.grid_size\n",
        "            )\n",
        "            self.spline_weight.data.copy_(\n",
        "                (self.scale_spline if not self.enable_standalone_scale_spline else 1.0)\n",
        "                * self.curve2coeff(\n",
        "                    self.grid.T[self.spline_order : -self.spline_order],\n",
        "                    noise,\n",
        "                )\n",
        "            )\n",
        "            if self.enable_standalone_scale_spline:\n",
        "                # torch.nn.init.constant_(self.spline_scaler, self.scale_spline)\n",
        "                torch.nn.init.kaiming_uniform_(self.spline_scaler, a=math.sqrt(5) * self.scale_spline)\n",
        "\n",
        "    def b_splines(self, x: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Compute the B-spline bases for the given input tensor.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: B-spline bases tensor of shape (batch_size, in_features, grid_size + spline_order).\n",
        "        \"\"\"\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "\n",
        "        grid: torch.Tensor = (\n",
        "            self.grid\n",
        "        )  # (in_features, grid_size + 2 * spline_order + 1)\n",
        "        x = x.unsqueeze(-1)\n",
        "        bases = ((x >= grid[:, :-1]) & (x < grid[:, 1:])).to(x.dtype)\n",
        "        for k in range(1, self.spline_order + 1):\n",
        "            bases = (\n",
        "                (x - grid[:, : -(k + 1)])\n",
        "                / (grid[:, k:-1] - grid[:, : -(k + 1)])\n",
        "                * bases[:, :, :-1]\n",
        "            ) + (\n",
        "                (grid[:, k + 1 :] - x)\n",
        "                / (grid[:, k + 1 :] - grid[:, 1:(-k)])\n",
        "                * bases[:, :, 1:]\n",
        "            )\n",
        "\n",
        "        assert bases.size() == (\n",
        "            x.size(0),\n",
        "            self.in_features,\n",
        "            self.grid_size + self.spline_order,\n",
        "        )\n",
        "        return bases.contiguous()\n",
        "\n",
        "    def curve2coeff(self, x: torch.Tensor, y: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Compute the coefficients of the curve that interpolates the given points.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n",
        "            y (torch.Tensor): Output tensor of shape (batch_size, in_features, out_features).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Coefficients tensor of shape (out_features, in_features, grid_size + spline_order).\n",
        "        \"\"\"\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "        assert y.size() == (x.size(0), self.in_features, self.out_features)\n",
        "\n",
        "        A = self.b_splines(x).transpose(\n",
        "            0, 1\n",
        "        )  # (in_features, batch_size, grid_size + spline_order)\n",
        "        B = y.transpose(0, 1)  # (in_features, batch_size, out_features)\n",
        "        solution = torch.linalg.lstsq(\n",
        "            A, B\n",
        "        ).solution  # (in_features, grid_size + spline_order, out_features)\n",
        "        result = solution.permute(\n",
        "            2, 0, 1\n",
        "        )  # (out_features, in_features, grid_size + spline_order)\n",
        "\n",
        "        assert result.size() == (\n",
        "            self.out_features,\n",
        "            self.in_features,\n",
        "            self.grid_size + self.spline_order,\n",
        "        )\n",
        "        return result.contiguous()\n",
        "\n",
        "    @property\n",
        "    def scaled_spline_weight(self):\n",
        "        return self.spline_weight * (\n",
        "            self.spline_scaler.unsqueeze(-1)\n",
        "            if self.enable_standalone_scale_spline\n",
        "            else 1.0\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        assert x.size(-1) == self.in_features\n",
        "        original_shape = x.shape\n",
        "        x = x.reshape(-1, self.in_features)\n",
        "\n",
        "        base_output = F.linear(self.base_activation(x), self.base_weight)\n",
        "        spline_output = F.linear(\n",
        "            self.b_splines(x).view(x.size(0), -1),\n",
        "            self.scaled_spline_weight.view(self.out_features, -1),\n",
        "        )\n",
        "        output = base_output + spline_output\n",
        "\n",
        "        output = output.reshape(*original_shape[:-1], self.out_features)\n",
        "        return output\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def update_grid(self, x: torch.Tensor, margin=0.01):\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "        batch = x.size(0)\n",
        "\n",
        "        splines = self.b_splines(x)  # (batch, in, coeff)\n",
        "        splines = splines.permute(1, 0, 2)  # (in, batch, coeff)\n",
        "        orig_coeff = self.scaled_spline_weight  # (out, in, coeff)\n",
        "        orig_coeff = orig_coeff.permute(1, 2, 0)  # (in, coeff, out)\n",
        "        unreduced_spline_output = torch.bmm(splines, orig_coeff)  # (in, batch, out)\n",
        "        unreduced_spline_output = unreduced_spline_output.permute(\n",
        "            1, 0, 2\n",
        "        )  # (batch, in, out)\n",
        "\n",
        "        # sort each channel individually to collect data distribution\n",
        "        x_sorted = torch.sort(x, dim=0)[0]\n",
        "        grid_adaptive = x_sorted[\n",
        "            torch.linspace(\n",
        "                0, batch - 1, self.grid_size + 1, dtype=torch.int64, device=x.device\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        uniform_step = (x_sorted[-1] - x_sorted[0] + 2 * margin) / self.grid_size\n",
        "        grid_uniform = (\n",
        "            torch.arange(\n",
        "                self.grid_size + 1, dtype=torch.float32, device=x.device\n",
        "            ).unsqueeze(1)\n",
        "            * uniform_step\n",
        "            + x_sorted[0]\n",
        "            - margin\n",
        "        )\n",
        "\n",
        "        grid = self.grid_eps * grid_uniform + (1 - self.grid_eps) * grid_adaptive\n",
        "        grid = torch.concatenate(\n",
        "            [\n",
        "                grid[:1]\n",
        "                - uniform_step\n",
        "                * torch.arange(self.spline_order, 0, -1, device=x.device).unsqueeze(1),\n",
        "                grid,\n",
        "                grid[-1:]\n",
        "                + uniform_step\n",
        "                * torch.arange(1, self.spline_order + 1, device=x.device).unsqueeze(1),\n",
        "            ],\n",
        "            dim=0,\n",
        "        )\n",
        "\n",
        "        self.grid.copy_(grid.T)\n",
        "        self.spline_weight.data.copy_(self.curve2coeff(x, unreduced_spline_output))\n",
        "\n",
        "    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n",
        "        \"\"\"\n",
        "        Compute the regularization loss.\n",
        "\n",
        "        This is a dumb simulation of the original L1 regularization as stated in the\n",
        "        paper, since the original one requires computing absolutes and entropy from the\n",
        "        expanded (batch, in_features, out_features) intermediate tensor, which is hidden\n",
        "        behind the F.linear function if we want an memory efficient implementation.\n",
        "\n",
        "        The L1 regularization is now computed as mean absolute value of the spline\n",
        "        weights. The authors implementation also includes this term in addition to the\n",
        "        sample-based regularization.\n",
        "        \"\"\"\n",
        "        l1_fake = self.spline_weight.abs().mean(-1)\n",
        "        regularization_loss_activation = l1_fake.sum()\n",
        "        p = l1_fake / regularization_loss_activation\n",
        "        regularization_loss_entropy = -torch.sum(p * p.log())\n",
        "        return (\n",
        "            regularize_activation * regularization_loss_activation\n",
        "            + regularize_entropy * regularization_loss_entropy\n",
        "        )\n",
        "\n",
        "\n",
        "class KAN(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        layers_hidden,\n",
        "        grid_size=5,\n",
        "        spline_order=3,\n",
        "        scale_noise=0.1,\n",
        "        scale_base=1.0,\n",
        "        scale_spline=1.0,\n",
        "        base_activation=torch.nn.SiLU,\n",
        "        grid_eps=0.02,\n",
        "        grid_range=[-1, 1],\n",
        "    ):\n",
        "        super(KAN, self).__init__()\n",
        "        self.grid_size = grid_size\n",
        "        self.spline_order = spline_order\n",
        "\n",
        "        self.layers = torch.nn.ModuleList()\n",
        "        for in_features, out_features in zip(layers_hidden, layers_hidden[1:]):\n",
        "            self.layers.append(\n",
        "                KANLinear(\n",
        "                    in_features,\n",
        "                    out_features,\n",
        "                    grid_size=grid_size,\n",
        "                    spline_order=spline_order,\n",
        "                    scale_noise=scale_noise,\n",
        "                    scale_base=scale_base,\n",
        "                    scale_spline=scale_spline,\n",
        "                    base_activation=base_activation,\n",
        "                    grid_eps=grid_eps,\n",
        "                    grid_range=grid_range,\n",
        "                )\n",
        "            )\n",
        "\n",
        "    def forward(self, x: torch.Tensor, update_grid=False):\n",
        "        for layer in self.layers:\n",
        "            if update_grid:\n",
        "                layer.update_grid(x)\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n",
        "        return sum(\n",
        "            layer.regularization_loss(regularize_activation, regularize_entropy)\n",
        "            for layer in self.layers\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8GRnrpnDuK-"
      },
      "outputs": [],
      "source": [
        "\n",
        "class PowerfulAutoencoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(PowerfulAutoencoder, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=4, stride=2, padding=1),  # (128, 128, 3) -> (64, 64, 32)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1), # (64, 64, 32) -> (32, 32, 64)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1), # (32, 32, 64) -> (16, 16, 128)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1), # (16, 16, 128) -> (8, 8, 256)\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            #nn.Linear(8*8*256, latent_dim)  # (8*8*256) -> (latent_dim)\n",
        "            KANLinear(8*8*256, latent_dim)\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 8*8*256),  # (latent_dim) -> (8*8*256)\n",
        "            nn.Unflatten(1, (256, 8, 8)),\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1), # (8, 8, 256) -> (16, 16, 128)\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1), # (16, 16, 128) -> (32, 32, 64)\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1), # (32, 32, 64) -> (64, 64, 32)\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 3, kernel_size=4, stride=2, padding=1), # (64, 64, 32) -> (128, 128, 3)\n",
        "            nn.Sigmoid()  # Use sigmoid if your image pixels are in the range [0, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        x_reconstructed = self.decoder(z)\n",
        "        return x_reconstructed,z\n",
        "\n",
        "\n",
        "def loss_function(reconstructed, original, latent, lambda_reg=0.1):\n",
        "    reconstruction_loss = nn.MSELoss()(reconstructed, original)\n",
        "    latent_reg_loss = torch.mean(torch.norm(latent, p=2, dim=1))\n",
        "    total_loss = reconstruction_loss + lambda_reg * latent_reg_loss\n",
        "    return total_loss, reconstruction_loss, latent_reg_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-_-ubk3iyRLs",
        "outputId": "ce8e4e13-8028-49e1-9db5-0cf2eab2ca20"
      },
      "outputs": [],
      "source": [
        "dataset = torch.tensor(dataset_norm, dtype=torch.float32)\n",
        "# Create DataLoader\n",
        "batch_size = 32\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "seed = 5\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Check if CUDA is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "model = PowerfulAutoencoder(latent_dim=16).to(device)\n",
        "print(model)\n",
        "# Weight initialization function\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "        nn.init.kaiming_normal_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):\n",
        "        nn.init.kaiming_normal_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 30\n",
        "lambda_reg = 1e-6\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    train_latent_loss = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)  # Move data to GPU\n",
        "\n",
        "        # Forward pass\n",
        "        output,latent = model(data)\n",
        "        loss, reconstruction_loss, latent_reg_loss = loss_function(output,data,latent,lambda_reg=lambda_reg)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        train_latent_loss += latent_reg_loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    train_latent_loss /= len(train_loader)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_latent_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            data = data.to(device)  # Move data to GPU\n",
        "\n",
        "            # Forward pass\n",
        "            output,latent = model(data)\n",
        "            loss, reconstruction_loss, latent_reg_loss = loss_function(output,data,latent,lambda_reg=lambda_reg)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            test_latent_loss += latent_reg_loss.item()\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    test_latent_loss /= len(test_loader)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.6f}, Test Loss: {test_loss:.6f},Train Latent loss: {train_latent_loss:.6f}, Test Latent Loss: {test_latent_loss:.6f}')\n",
        "\n",
        "print('Training complete')\n",
        "\n",
        "# Save the trained model\n",
        "model_path = content_path + '/AE_KAN.pth'\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print('Model saved to autoencoder.pth')\n",
        "\n",
        "# Plot the training and testing losses\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
        "plt.plot(range(1, num_epochs + 1), test_losses, label='Test Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Testing Loss per Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "plot loss in log scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "qa25YX15X9Tr",
        "outputId": "9673430f-0d60-4661-f8d8-c03f486299cf"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.semilogy(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
        "plt.semilogy(range(1, num_epochs + 1), test_losses, label='Test Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Testing Loss per Epoch/logscale')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mpmOoGj4E6Oy",
        "outputId": "a0f8b2fa-db44-4b9e-acae-95c3403d5e3a"
      },
      "outputs": [],
      "source": [
        "\n",
        "def visualize_reconstruction(model, data_loader, num_images=5):\n",
        "    model.eval()\n",
        "    data_iter = iter(data_loader)\n",
        "\n",
        "    original_data = next(data_iter).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        encoded_data = model.encoder(original_data)\n",
        "        reconstructed_data = model.decoder(encoded_data)\n",
        "\n",
        "    original_data = original_data.cpu().numpy()\n",
        "    reconstructed_data = reconstructed_data.cpu().numpy()\n",
        "\n",
        "    fig, axes = plt.subplots(num_images, 6, figsize=(18, num_images * 3))\n",
        "    for i in range(num_images):\n",
        "        for j in range(3):\n",
        "            ax = axes[i, j*2]\n",
        "\n",
        "            ax.imshow(original_data[i, j], cmap='viridis')\n",
        "            ax.set_title(f'Original - Channel {j+1}')\n",
        "            ax.axis('off')\n",
        "\n",
        "            ax = axes[i, j*2 + 1]\n",
        "            ax.imshow(reconstructed_data[i, j], cmap='viridis')\n",
        "            ax.set_title(f'Reconstructed - Channel {j+1}')\n",
        "            ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize some reconstructions\n",
        "visualize_reconstruction(model, test_loader, num_images=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PIS3d6NLHiUr",
        "outputId": "ffedb509-8796-43e0-9f73-142d39fe8bdf"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def visualize_reconstruction(model, data_loader, num_images=5):\n",
        "    model.eval()\n",
        "    # data_iter = iter(data_loader)\n",
        "    # original_data = next(data_iter).to(device)\n",
        "    count = 0\n",
        "    for data in data_loader:\n",
        "        count += 1\n",
        "        if count == 7:\n",
        "            data_iter = data.to(device)\n",
        "            break\n",
        "\n",
        "    original_data = data_iter.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        encoded_data = model.encoder(original_data)\n",
        "        reconstructed_data = model.decoder(encoded_data)\n",
        "\n",
        "    original_data = original_data.cpu().numpy()\n",
        "    reconstructed_data = reconstructed_data.cpu().numpy()\n",
        "\n",
        "    fig, axes = plt.subplots(3, num_images, figsize=(num_images * 5, 15))  # Adjusting rows and columns\n",
        "    for i in range(num_images):\n",
        "        # Display Input (Original) Image\n",
        "        ax = axes[0, i]\n",
        "        img = ax.imshow(original_data[i, 2], cmap='viridis')\n",
        "        ax.set_title('Input')\n",
        "        ax.axis('off')\n",
        "        fig.colorbar(img, ax=ax, orientation='vertical')\n",
        "\n",
        "        # Display Reconstructed Image\n",
        "        ax = axes[1, i]\n",
        "        img = ax.imshow(reconstructed_data[i, 2], cmap='viridis')\n",
        "        ax.set_title('Reconstruction')\n",
        "        ax.axis('off')\n",
        "        fig.colorbar(img, ax=ax, orientation='vertical')\n",
        "\n",
        "        # Display Error Image\n",
        "        ax = axes[2, i]\n",
        "        error_img = np.abs(original_data[i, 2] - reconstructed_data[i, 2])\n",
        "        img = ax.imshow(error_img, cmap='viridis')\n",
        "        ax.set_title('Error')\n",
        "        ax.axis('off')\n",
        "        fig.colorbar(img, ax=ax, orientation='vertical')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize some reconstructions\n",
        "visualize_reconstruction(model, test_loader, num_images=5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFl-e94aafCE",
        "outputId": "21662647-0d22-4f6b-f1bd-f2d51ed64592"
      },
      "outputs": [],
      "source": [
        "from skimage.metrics import structural_similarity as ssim\n",
        "# Define RRMSE and SSIM functions\n",
        "def rrmse(img1, img2):\n",
        "    return np.sqrt(np.mean((img1 - img2) ** 2)) / np.sqrt(np.mean(img1 ** 2))\n",
        "\n",
        "def compute_ssim(img1, img2):\n",
        "    return ssim(img1, img2, data_range=img2.max() - img2.min(), multichannel=True,win_size=5, channel_axis=-1)\n",
        "\n",
        "def compute_psnr(img1, img2):\n",
        "    mse = np.mean((img1 - img2) ** 2)\n",
        "    if mse == 0:\n",
        "        return float('inf')\n",
        "    max_pixel = 1.0  # Assuming the pixel values are normalized between 0 and 1\n",
        "    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
        "    return psnr\n",
        "\n",
        "# Compute RRMSE and SSIM for the entire test dataset\n",
        "def evaluate_model(model, data_loader):\n",
        "    model.eval()\n",
        "    rrmse_values = []\n",
        "    ssim_values = []\n",
        "    mse_values = []\n",
        "    psnr_values = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in data_loader:\n",
        "            data = data.to(device)\n",
        "\n",
        "            reconstructed_data,_ = model(data)\n",
        "            original_data = data.cpu().numpy()\n",
        "            reconstructed_data = reconstructed_data.cpu().numpy()\n",
        "\n",
        "            for i in range(original_data.shape[0]):\n",
        "                original_img = original_data[i].transpose(1, 2, 0)\n",
        "                reconstructed_img = reconstructed_data[i].transpose(1, 2, 0)\n",
        "\n",
        "                rrmse_value = rrmse(original_img, reconstructed_img)\n",
        "\n",
        "                ssim_value = compute_ssim(original_img, reconstructed_img)\n",
        "\n",
        "                mse = np.mean((original_img- reconstructed_img) ** 2)\n",
        "\n",
        "                psnr_value = compute_psnr(original_img, reconstructed_img)\n",
        "\n",
        "                rrmse_values.append(rrmse_value)\n",
        "                ssim_values.append(ssim_value)\n",
        "                mse_values.append(mse)\n",
        "                psnr_values.append(psnr_value)\n",
        "\n",
        "    mean_rrmse = np.mean(rrmse_values)\n",
        "    mean_ssim = np.mean(ssim_values)\n",
        "    mean_mse = np.mean(mse_values)\n",
        "    mean_psnr = np.mean(psnr_values)\n",
        "    print(\"metric for AE without KAN\")\n",
        "    #print(\"metric for AE\")\n",
        "    print(f'Mean RRMSE: {mean_rrmse:.4f}')\n",
        "    print(f'Mean SSIM: {mean_ssim:.4f}')\n",
        "    print(f'Mean MSE: {mean_mse:.6f}')\n",
        "    print(f'Mean PSNR: {mean_psnr:.4f}')\n",
        "\n",
        "    return mean_rrmse, mean_ssim\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "mean_rrmse, mean_ssim = evaluate_model(model, test_loader)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
